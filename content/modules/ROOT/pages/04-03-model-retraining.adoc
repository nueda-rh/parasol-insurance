= モデルの再学習（オプション）
include::_attributes.adoc[]

== はじめに

YOLO モデルを事故画像を識別できるようファインチューニングするには、事故状況を表すラベルが付いた車の画像データセットが必要です。ウェブ上で公開されているデータセット(from https://universe.roboflow.com/accident-detection-ffdrf/accident-detection-8dvh5/dataset/1[RoboFlow,window=_blank] から) では、画像はラベル付けされ、トレーニング データセットと検証データセットに分割されています。ここではこのトレーニング セットを使用して、現在の YOLO モデルをファインチューニングします。
[.bordershadow]
image::04/roboflow-test-images.png[roboflow images]

== トレーニング データ

[%collapsible]
====
1. モデルに検出するように教えたいオブジェクトのエンコード クラスは、0 - 'moderate' と 1 - 'severe' です。
2. データセット (data) 用のフォルダーを作成し、その中に 'train' と 'valid' の 2 つのサブフォルダーを作成します。各サブフォルダ内に、「images」と「labels」の 2 つのサブフォルダを作成しました。
3. 各画像の「labels」サブフォルダには注釈テキスト ファイルがあります。注釈テキスト ファイルの名前は画像ファイルと同じです。
====

== (オプション)詳細なコードと実行

このパートはオプション演習となります。そのため一旦スキップし、あとで実行することも可能です。
このセクションについてさらに詳しく知りたい場合は、以下の指示に従ってください。

次のトレーニング データ セットを用意しました。これは zip ファイルとして提供され、オブジェクトストレージにあります: `accident-sample.zip` (この {ic-lab} ではモデルを完全にファインチューニングする時間がないため、トレーニング データ セットのサンプルを使用します)。


- 実行中のワークベンチで、フォルダ  `parasol-insurance/lab-materials/04` に移動します。
- `04-03-model-retraining.ipynb` というノートブックを探して開きます。
- ノートブックのセルを実行します。

== モデルのファインチューニング結果の解釈
[%collapsible]
====
次のトレーニング実行では、完全なデータセットの結果が表示されます。

まず、「エポック」とは何かを理解しましょう。機械学習モデルは、特定のデータセットを使用してトレーニングされます。準備したデータセット全体がモデルの学習アルゴリズムを通過するたびに、１つのエポックが完了したとみなされます。したがって、機械学習におけるエポックとは、与えられたトレーニングデータセットを使ってモデルが何回学習されたかを指します。

以下のトレーニング実行では、バッチ サイズが 32 (つまり、32 枚の画像が同時にインプットされる)、7エポックでのトレーニング実行を確認できます。これは、次のコード スニペットによって設定されました。

results = model.train(data='./datasets/accident-full/data.yaml', epochs=7, imgsz=640, batch=32)

トレーニング実行では、各エポックにトレーニング フェーズと検証フェーズの両方の概要が表示されます。行 1 と 2 にはトレーニング フェーズの結果が表示され、行 3 と 4 には各エポックの検証フェーズの結果が表示されます。

image::04/model-retraining-summary.png[再トレーニングの概要]

トレーニング フェーズには損失関数のエラー量の計算が含まれるため、ここで最も重要なメトリックは box_loss と cls_loss です。

* box_loss は、検出された境界ボックスのエラー量を示します。

* cls_loss は、検出されたオブジェクト クラスのエラー量を示します。

モデルがデータから実際に何かを学習した場合、これらの値はエポックごとに減少するはずです。+
前のスクリーンショットでは、box_loss は最初のエポックの 1.219 から最後のエポックの 0.8386 に減少し、cls_loss は 1.875 から 0.9001 に減少しました。

もう 1 つの重要な品質メトリックは、平均精度である mAP50-95 です。モデルが学習して改善した場合、精度はエポックごとに増加するはずです。 +
前のスクリーンショットでは、mAP50-95 が 0.423 (epoch1) から 0.755 (epoch7) に増加しました。

トレーニング全体を通じて GPU が使用され、メモリ消費量が 13 GB を少し超えたこともわかります。

最後のエポック後に許容できる精度が得られなかった場合は、エポック数を増やしてトレーニングを再度実行できます。また、batch、lr0、lrf などの他のパラメータを調整したり、使用しているオプティマイザーを変更したりすることもできます。

トレーニング中は、各エポック後にトレーニング済みのモデルを /runs/detect/train/weights/last.pt ファイルにエクスポートし、最も精度の高いモデルを /runs/detect/train/weights/best.pt ファイルにエクスポートします。そのため、トレーニングが終了したら、本番環境で使用できる best.pt ファイルを取得できます。

Note:  実際のケースでは、ここで示したよりも多くのエポックでトレーニングを実行する必要があり、この例のようにわずか 16 分ではなく、トレーニングが完了するまで数時間または数日待つ準備をする必要があります。
====
