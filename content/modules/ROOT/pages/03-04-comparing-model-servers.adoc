= 2つのLLMを比較する
include::_attributes.adoc[]

これまでのところ、この {ic-lab} にはモデル https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2[Mistral-7B Instruct v2,window=_blank] を使用してきました。他のモデルよりも軽量ですが、それでもまだかなり重く、実行するには大きな GPU が必要です。CPU のみで動作するより軽量なモデルでも同等の結果が得られるでしょうか？試してみましょう！

この演習では、以前のモデルを、https://huggingface.co/google/flan-t5-small[flan-t5-large,window=_blank]と呼ばれるはるかに小さいLLMと比較します。結果を比較し、より小さいモデルがユースケースに十分適しているかどうかを確認します。

`parasol-insurance/lab-materials/03` フォルダから、`03-04-comparing-model-servers.ipynb` というノートブックを開き、指示に従ってください。

完了したら、ノートブックを閉じて次のページに進みます。
