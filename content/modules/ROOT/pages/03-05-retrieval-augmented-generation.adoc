=  Retrieval-Augmented Generation 検索強化型生成 - モデルの機能拡張
include::_attributes.adoc[]

LLMは非常に優れたツールですが、その能力は、トレーニングされた知識や情報の範囲に限られます。結局のところ、人は自分が知っていることしか知らないのです。しかし、トレーニングデータにない質問をする必要がある場合はどうでしょうか？あるいは、トレーニングデータにはないが、それに関連する質問をする必要がある場合はどうでしょうか？

この問題を解決する方法はいくつかあり、利用可能なリソースや、それに費やすことのできる時間や費用によって異なります。以下にいくつかのオプションを紹介します。

- 必要な情報を含めるためにモデルを完全に再トレーニングする。LLMの場合、文字通り数千のGPUを数週間稼働させることができる企業は、世界でもほんの一握りしかありません。
- この新しい情報でモデルを微調整する。これにははるかに少ないリソースしか必要とせず、通常は数時間または数分で完了します（モデルのサイズによります）。ただし、モデルの再トレーニングは行われないため、新しい情報が回答に完全に統合されない場合があります。微調整は、特定の文脈や語彙のより深い理解を得ることに優れていますが、新しい知識の追加にはやや劣ります。また、情報を追加する場合は、いずれにしてもモデルの再トレーニングと再展開を行う必要があります。
この新しい情報をデータベースに入れ、クエリーに関連する部分を抽出して、LLMに送信する前にこのクエリーにコンテクストとして追加します。この技術は、**Retrieval Augmented Generation（RAG）**と呼ばれています。この新しい知識を活用するためにモデルを再トレーニングしたり、微調整する必要がないため、いつでも簡単に更新できるという点で興味深いものです。

https://milvus.io/[Milvus,window=_blank] を使用してベクトルデータベースをすでに用意しており、 https://www.dmv.ca.gov/portal/handbook/california-driver-handbook/[California Driver's Handbook,window=_blank] の内容を ( https://www.ibm.com/topics/embedding[Embeddings,window=_blank] の形式で) 格納しています。

この演習では、RAGテクニックを使用して**請求に関するいくつかのクエリを実行**し、LLMを修正することなく、この新しい知識がどのように役立つかを確認します。

`parasol-insurance/lab-materials/03`フォルダから、`03-05-retrieval-augmented-generation.ipynb`というノートブックを開き、指示に従ってください。

完了したら、ノートブックを閉じて次のページに進みます。
