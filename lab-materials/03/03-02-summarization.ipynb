{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "4ad2cc4e-31ec-4648-b0fe-6632f2bdbc36",
            "metadata": {},
            "source": [
                "# LLMを使用したテキストの要約\n",
                "\n",
                "LLMは言語を理解するため、翻訳や要約などのタスクに適しています。  \n",
                "例えばこのNotebookでは、LLMを使用して、保険の請求に関する文章を要約します。"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2a4e2b81-0e10-4390-a7b8-5ddfda53a3e3",
            "metadata": {},
            "source": [
                "### 必要なライブラリとインポート\n",
                "\n",
                "Labの指示に従って適切なワークベンチイメージを選択して起動した場合、必要なすべてのライブラリがすでにインストールされているはずです。もしインストールされていない場合は、次のセルの最初の行のコメントを外して正しいパッケージをすべてインストールしてください。その後、必要なライブラリをインポートします。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d61c595d-967e-47de-a598-02b5d1ccec85",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# !pip install --no-cache-dir --no-dependencies --disable-pip-version-check -r requirements.txt # 正しいワークベンチイメージを選択していない場合のみ、コメントを外してください\n",
                "\n",
                "import json\n",
                "import os\n",
                "from os import listdir\n",
                "from os.path import isfile, join\n",
                "from langchain.chains import LLMChain\n",
                "from langchain_community.llms import VLLMOpenAI\n",
                "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
                "from langchain.prompts.chat import (\n",
                "    SystemMessagePromptTemplate,\n",
                "    HumanMessagePromptTemplate,\n",
                "    ChatPromptTemplate\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c428fbad-2345-4536-b687-72416d6b9b15",
            "metadata": {},
            "source": [
                "### Langchainパイプライン\n",
                "\n",
                "Langchainを使用して、要約のパイプラインを定義します。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "77f95a70-89fb-4e21-a51c-24e862b7953e",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# LLM推論APIのURL\n",
                "inference_server_url = \"_INFERENCE_URL_LLM_\"\n",
                "\n",
                "# LLMの定義\n",
                "llm = VLLMOpenAI(\n",
                "    openai_api_key=\"EMPTY\",\n",
                "    openai_api_base= f\"{inference_server_url}/v1\",\n",
                "    model_name=\"elyza\",\n",
                "    top_p=0.92,\n",
                "    temperature=0.01,\n",
                "    max_tokens=512,\n",
                "    presence_penalty=1.03,\n",
                "    streaming=True,\n",
                "    callbacks=[StreamingStdOutCallbackHandler()]\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "20b950bc-4d73-49e5-a35b-083a784edd50",
            "metadata": {},
            "source": [
                "以下は、要約タスクに対してフォーマットされた**テンプレート**です。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f8bb7517-faa2-43ed-a95d-835de975f916",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "system_template_string = \"\"\"\n",
                "あなたは、親切で、礼儀正しく、正直なアシスタントです。\n",
                "常に気配りと尊重をもって接し、真摯にサポートします。できる限り有用な返答を提供しますが、安全を確保します。\n",
                "有害で、倫理に反する、偏見のある、または否定的な内容は避けます。返答が公正でポジティブなものであることを確認します。\n",
                "\"\"\"\n",
                "\n",
                "user_template_string = \"\"\"\n",
                "提供された文章を要約して下さい。要約は5項目以内の箇条書きにしてください。\n",
                "\n",
                "### 文章:\n",
                "{input}\n",
                "\n",
                "### 要約:\n",
                "\"\"\"\n",
                "\n",
                "system_template = SystemMessagePromptTemplate.from_template(system_template_string)\n",
                "user_template = HumanMessagePromptTemplate.from_template(user_template_string)\n",
                "\n",
                "PROMPT = ChatPromptTemplate.from_messages([system_template, user_template])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9cbe2119-2128-4432-aed1-126e9c8c034f",
            "metadata": {},
            "source": [
                "モデルにクエリを投げるために使用する**会話**オブジェクトを作成します。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0e6d9f32-d4ae-4c2f-b513-d520413d2cc8",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "conversation = LLMChain(llm=llm,\n",
                "                        prompt=PROMPT,\n",
                "                        verbose=False\n",
                "                        )"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "849fbd67-220c-4a02-8e4e-7e0d1aa91588",
            "metadata": {},
            "source": [
                "モデルにクエリする準備が整いました。\n",
                "\n",
                "`claims`フォルダーには、受信される可能性のある請求文章の例がJSONファイルで保存されています。これらのファイルを読み込んで表示し、その後にLLMが作成した要約を表示します。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ca714bca-7cec-4afc-b275-fa389c05a993",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# 請求文章の読み取り\n",
                "claims_path = 'claims'\n",
                "onlyfiles = [f for f in listdir(claims_path) if isfile(join(claims_path, f))]\n",
                "\n",
                "claims = {}\n",
                "\n",
                "for filename in onlyfiles:\n",
                "    with open(os.path.join(claims_path, filename), 'r') as file:\n",
                "        data = json.load(file)\n",
                "    claims[filename] = data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dac009d5-d558-4258-9735-4fb0de46c309",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "for filename in onlyfiles:\n",
                "    print(f\"***************************\")\n",
                "    print(f\"* 請求: {filename}\")\n",
                "    print(f\"***************************\")\n",
                "    print(\"元の文章:\")\n",
                "    print(\"-----------------\")\n",
                "    print(f\"件名: {claims[filename]['subject']}\\n内容:\\n{claims[filename]['content']}\\n\\n\")\n",
                "    print('要約:')\n",
                "    print(\"--------\")\n",
                "    summary_input = f\"件名: {claims[filename]['subject']}\\n内容:\\n{claims[filename]['content']}\"\n",
                "    conversation.predict(input=summary_input);\n",
                "    print(\"\\n\\n                          ----====----\\n\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.11",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}