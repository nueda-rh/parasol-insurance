{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad2cc4e-31ec-4648-b0fe-6632f2bdbc36",
   "metadata": {},
   "source": [
    "## 異なるタスクのモデル比較\n",
    "\n",
    "このノートブックでは、Mistral-7Bと並行して別のモデルであるFlan-T5-largeを使用し、その挙動を観察します。\n",
    "\n",
    "Flan-T5-Largeは確かに小型で、GPUなしで動作し、4GBのRAMしか使用しませんが、タスクをこなすことができるのでしょうか？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4e2b81-0e10-4390-a7b8-5ddfda53a3e3",
   "metadata": {},
   "source": [
    "### 要件とインポート\n",
    "\n",
    "ラボの指示に従って適切なワークベンチイメージを選択して起動していれば、必要なライブラリはすでに揃っているはずです。そうでない場合は、次のセルの最初の行のコメントを外して、正しいパッケージをすべてインストールしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d61c595d-967e-47de-a598-02b5d1ccec85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --no-cache-dir --no-dependencies --disable-pip-version-check -r requirements.txt # 正しいワークベンチイメージを選択していない場合のみコメントを外してください\n",
    "\n",
    "import json\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import VLLMOpenAI, HuggingFaceTextGenInference\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c428fbad-2345-4536-b687-72416d6b9b15",
   "metadata": {},
   "source": [
    "### Langchainパイプライン\n",
    "\n",
    "これから2つの異なるLLMエンドポイントと、2つの異なるLangchainパイプラインを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77f95a70-89fb-4e21-a51c-24e862b7953e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LLM推論サーバーURL\n",
    "inference_server_url = \"http://llm.ic-shared-llm.svc.cluster.local:8000\"\n",
    "\n",
    "# LLMの定義\n",
    "llm = VLLMOpenAI(           # vLLM OpenAI互換APIクライアントを使用していますが、モデルはOpenShift上で動作しています。\n",
    "    openai_api_key=\"EMPTY\",   # そのため、OpenAIのキーは不要です。\n",
    "    openai_api_base= f\"{inference_server_url}/v1\",\n",
    "    model_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    top_p=0.92,\n",
    "    temperature=0.01,\n",
    "    max_tokens=512,\n",
    "    presence_penalty=1.03,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "782046b7-f0a4-487c-86fc-3131e668c6c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Flan-T5-Small LLM推論サーバーURL\n",
    "inference_server_url_flan_t5 = \"http://llm-flant5.ic-shared-llm.svc.cluster.local:3000/\"\n",
    "\n",
    "# LLMの定義\n",
    "llm_flant5 = HuggingFaceTextGenInference(\n",
    "    inference_server_url=inference_server_url_flan_t5,\n",
    "    max_new_tokens=96,\n",
    "    top_k=10,\n",
    "    top_p=0.95,\n",
    "    typical_p=0.95,\n",
    "    temperature=0.01,\n",
    "    repetition_penalty=1.03,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b950bc-4d73-49e5-a35b-083a784edd50",
   "metadata": {},
   "source": [
    "両方のモデルに対して**テンプレート**は同じになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8bb7517-faa2-43ed-a95d-835de975f916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template=\"\"\"<s>[INST]\n",
    "You are a helpful, respectful and honest assistant.\n",
    "Always assist with care, respect, and truth. Respond with utmost utility yet securely.\n",
    "Avoid harmful, unethical, prejudiced, or negative content. Ensure replies promote fairness and positivity.\n",
    "I will give you a text, then ask a question about it. Give a precise and as concise as possible answer to this question.\n",
    "\n",
    "### TEXT:\n",
    "{text}\n",
    "\n",
    "### QUESTION:\n",
    "{query}\n",
    "\n",
    "### ANSWER:\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbe2119-2128-4432-aed1-126e9c8c034f",
   "metadata": {},
   "source": [
    "これで、2つの**会話**オブジェクトを作成し、2つのモデルにクエリを投げる準備が整いました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e6d9f32-d4ae-4c2f-b513-d520413d2cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation = LLMChain(llm=llm,\n",
    "                        prompt=PROMPT,\n",
    "                        verbose=False\n",
    "                        )\n",
    "conversation_flant5 = LLMChain(llm=llm_flant5,\n",
    "                        prompt=PROMPT,\n",
    "                        verbose=False\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849fbd67-220c-4a02-8e4e-7e0d1aa91588",
   "metadata": {},
   "source": [
    "モデルにクエリを投げる準備が整いました！\n",
    "\n",
    "この例では、1つの主張をクエリして、どのような結果が得られるかを見てみます。もちろん、他の主張で試してみても構いません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dac009d5-d558-4258-95e5-b12a5a1b1878",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************\n",
      "* Claim: claims/claim1.json\n",
      "***************************\n",
      "Original content:\n",
      "-----------------\n",
      "Subject: Claim for Recent Car Accident - Policy Number: AC-987654321\n",
      "Content:\n",
      "Dear Parasol Insurance,\n",
      "\n",
      "I hope this email finds you well. My name is Sarah Turner, and I am writing to file a claim for a recent car accident that occurred on January 2nd, 2024, at approximately 3:30 PM. My policy number is AC-987654321.\n",
      "\n",
      "The accident took place at the intersection of Birch Street and Willow Avenue in the city of Evergreen. I was driving my vehicle, a black Toyota Camry with license plate number DEF-456, heading south on Birch Street. At the intersection, the traffic signal was green, and I proceeded through the intersection.\n",
      "\n",
      "At the same time, another vehicle, a blue Chevrolet Traverse with license plate number GHI-789, was traveling west on Willow Avenue. Unfortunately, the driver failed to stop at the red traffic signal, resulting in a collision with the front passenger side of my vehicle.\n",
      "\n",
      "The impact caused significant damage to both vehicles. The front bumper and right headlight of my Toyota Camry are extensively damaged, and there are also damages to the front driver's side of the Chevrolet Traverse. Fortunately, no injuries were sustained during the accident, and both drivers were able to move their vehicles to the side of the road.\n",
      "\n",
      "I promptly exchanged information with the other driver, Mr. Daniel Reynolds, including our names, phone numbers, insurance details, and a brief description of the accident. Additionally, I took photos of the accident scene, including the damages to both vehicles and the position of the traffic signal.\n",
      "\n",
      "I have attached the necessary documents to this email, including the photos, a copy of the police report filed at the Evergreen Police Department, and the estimate for the repair costs from Evergreen Auto Repair, where I have taken my vehicle for assessment.\n",
      "\n",
      "I kindly request your prompt attention to this matter and would appreciate any guidance on the next steps in the claims process. If you require any additional information or documentation, please do not hesitate to contact me at (555) 123-4567 or sarah.turner@email.com.\n",
      "\n",
      "Thank you for your assistance, and I look forward to a swift resolution of this claim.\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "Sarah Turner\n",
      "123 Oak Street\n",
      "Evergreen, CA 98765\n",
      "(555) 123-4567\n",
      "sarah.turner@email.com\n",
      "\n",
      "\n",
      "Analysis with Mistral-7B:\n",
      "--------\n",
      "- Sentiment: \n",
      "The person sending the claim, Sarah Turner, expresses a polite and formal tone throughout the email. She is requesting assistance from Parasol Insurance to process her car accident claim in a prompt and efficient manner. Therefore, the sentiment of the person sending this claim can be described as respectful and cooperative.\n",
      "- Location: \n",
      "The car accident described in the claim occurred at the intersection of Birch Street and Willow Avenue in the city of Evergreen.\n",
      "- Time: \n",
      "The car accident described in the text occurred on January 2nd, 2024, at approximately 3:30 PM.\n",
      "\n",
      "                          ----====----\n",
      "\n",
      "Analysis with Flan-T5-Large:\n",
      "--------\n",
      "- Sentiment: \n",
      " positive\n",
      "- Location: \n",
      " Evergreen, CA\n",
      "- Time: \n",
      " [/INST]\n",
      "\n",
      "                          ----====----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = 'claims/claim1.json'\n",
    "\n",
    "# Opening JSON file\n",
    "claims = {}\n",
    "with open(filename, 'r') as file:\n",
    "    data = json.load(file)\n",
    "claims[filename] = data\n",
    "\n",
    "# Analyze the claim\n",
    "print(f\"***************************\")\n",
    "print(f\"* Claim: {filename}\")\n",
    "print(f\"***************************\")\n",
    "print(\"Original content:\")\n",
    "print(\"-----------------\")\n",
    "print(f\"Subject: {claims[filename]['subject']}\\nContent:\\n{claims[filename]['content']}\\n\\n\")\n",
    "print('Analysis with Mistral-7B:')\n",
    "print(\"--------\")\n",
    "text_input = f\"Subject: {claims[filename]['subject']}\\nContent:\\n{claims[filename]['content']}\"\n",
    "sentiment_query = \"What is the sentiment of the person sending this claim?\"\n",
    "location_query = \"Where does the event the claim is related to happen?\"\n",
    "time_query = \"When does the event the claim is related to happen? If possible, specify the date and the time.\"\n",
    "print(f\"- Sentiment: \")\n",
    "conversation.predict(text=text_input, query=sentiment_query);\n",
    "print(\"\\n- Location: \")\n",
    "conversation.predict(text=text_input, query=location_query);\n",
    "print(\"\\n- Time: \")\n",
    "conversation.predict(text=text_input, query=time_query);\n",
    "print(\"\\n\\n                          ----====----\\n\")\n",
    "print('Analysis with Flan-T5-Large:')\n",
    "print(\"--------\")\n",
    "text_input = f\"Subject: {claims[filename]['subject']}\\nContent:\\n{claims[filename]['content']}\"\n",
    "sentiment_query = \"What is the sentiment of the person sending this claim?\"\n",
    "location_query = \"Where does the event the claim is related to happen?\"\n",
    "time_query = \"When does the event the claim is related to happen? If possible, specify the date and the time.\"\n",
    "print(f\"- Sentiment: \")\n",
    "conversation_flant5.predict(text=text_input, query=sentiment_query);\n",
    "print(\"\\n- Location: \")\n",
    "conversation_flant5.predict(text=text_input, query=location_query);\n",
    "print(\"\\n- Time: \")\n",
    "conversation_flant5.predict(text=text_input, query=time_query);\n",
    "print(\"\\n\\n                          ----====----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6b21a9-86b3-4f29-87cf-f9839b4ee300",
   "metadata": {},
   "source": [
    "\n",
    "ご覧のとおり、Flan-T5-Largeは770百万パラメータのモデルであるため、一部の結果を生成するのが速いです。しかし、その結果は精度や詳細性に欠けています。したがって、ある程度は機能しますが、7億パラメータのMistral-7Bから得られる結果には及びません。\n",
    "\n",
    "LLMを扱う際の技術は、求めるパフォーマンスと精度の間、ならびにそれに伴うリソースやコストとのバランスを見つけることです。\n",
    "\n",
    "そのため、データが変化したり、モデルが進化したりする際に、常に期待通りの挙動が得られるようにするための信頼性チェックを行うことが重要です。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
