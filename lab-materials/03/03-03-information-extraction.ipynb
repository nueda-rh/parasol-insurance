{
    "cells": [
     {
      "cell_type": "markdown",
      "id": "4ad2cc4e-31ec-4648-b0fe-6632f2bdbc36",
      "metadata": {},
      "source": [
       "## LLMを使用してテキストから情報を抽出する\n",
       "\n",
       "LLMは言語を「理解」するため、感情分析や情報抽出のようなタスクに適しています。\n",
       "\n",
       "このノートブックでは、クレームを分析して、書いた人の感情状態や事故の場所、時間を特定するためにLLMを使用します。"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "2a4e2b81-0e10-4390-a7b8-5ddfda53a3e3",
      "metadata": {},
      "source": [
       "### 必要条件とインポート\n",
       "\n",
       "ラボの指示に従って正しいワークベンチイメージを選択した場合、必要なライブラリはすでにインストールされています。そうでない場合は、次のセルの最初の行のコメントを外して、必要なパッケージをインストールしてください。"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "d61c595d-967e-47de-a598-02b5d1ccec85",
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "# !pip install --no-cache-dir --no-dependencies --disable-pip-version-check -r requirements.txt # 正しいワークベンチイメージを選択していない場合のみ、コメントを外してください\n",
       "\n",
       "import json\n",
       "import os\n",
       "from os import listdir\n",
       "from os.path import isfile, join\n",
       "from langchain.chains import LLMChain\n",
       "from langchain_community.llms import VLLMOpenAI\n",
       "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
       "from langchain.prompts import PromptTemplate"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "c428fbad-2345-4536-b687-72416d6b9b15",
      "metadata": {},
      "source": [
       "### Langchainパイプライン\n",
       "\n",
       "再び、Langchainを使用してタスクパイプラインを定義します。"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "77f95a70-89fb-4e21-a51c-24e862b7953e",
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "# LLM推論サーバーのURL\n",
       "inference_server_url = \"http://llm.ic-shared-llm.svc.cluster.local:8000\"\n",
       "\n",
       "# LLMの定義\n",
       "llm = VLLMOpenAI(           # vLLMのOpenAI互換APIクライアントを使用していますが、モデルはOpenShift上で実行されています。\n",
       "    openai_api_key=\"EMPTY\",   # OpenAIのキーは必要ありません。\n",
       "    openai_api_base= f\"{inference_server_url}/v1\",\n",
       "    model_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
       "    top_p=0.92,\n",
       "    temperature=0.01,\n",
       "    max_tokens=512,\n",
       "    presence_penalty=1.03,\n",
       "    streaming=True,\n",
       "    callbacks=[StreamingStdOutCallbackHandler()]\n",
       ")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "20b950bc-4d73-49e5-a35b-083a784edd50",
      "metadata": {},
      "source": [
       "次に、さまざまなタスクに使用する**テンプレート**を定義します。"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8bb7517-faa2-43ed-a95d-835de975f916",
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "template=\"\"\"<s>[INST]\n",
       "あなたは役立ち、尊敬を持ち、誠実なアシスタントです。\n",
       "常に注意深く、尊敬を持って、真実をもって支援してください。最大限に役立ちつつも、安全な方法で返信してください。\n",
       "有害、非倫理的、偏見に満ちた、または否定的な内容を避け、公平さと前向きさを促進する返信を心がけてください。\n",
       "次に示すテキストに基づいて質問に答えてください。できるだけ正確で簡潔な回答を提供してください。\n",
       "\n",
       "### テキスト:\n",
       "{text}\n",
       "\n",
       "### 質問:\n",
       "{query}\n",
       "\n",
       "### 回答:\n",
       "[/INST]\n",
       "\"\"\"\n",
       "PROMPT = PromptTemplate(input_variables=[\"text\", \"query\"], template=template)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "9cbe2119-2128-4432-aed1-126e9c8c034f",
      "metadata": {},
      "source": [
       "次に、モデルにクエリを送信するために使用する**会話**オブジェクトを作成します。"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e6d9f32-d4ae-4c2f-b513-d520413d2cc8",
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "conversation = LLMChain(llm=llm,\n",
       "                        prompt=PROMPT,\n",
       "                        verbose=False\n",
       "                        )"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "849fbd67-220c-4a02-8e4e-7e0d1aa91588",
      "metadata": {},
      "source": [
       "これでモデルにクエリを送信する準備が整いました！\n",
       "\n",
       "`claims`フォルダには、受け取ることができるクレームの例が含まれたJSONファイルがあります。それらのファイルを読み込み、表示し、その後LLMが行った分析を確認します。"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca714bca-7cec-4afc-b275-fa389c05a993",
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "# クレームを読み込み、辞書に追加\n",
       "\n",
       "claims_path = 'claims'\n",
       "onlyfiles = [f for f in listdir(claims_path) if isfile(join(claims_path, f))]\n",
       "\n",
       "claims = {}\n",
       "\n",
       "for filename in onlyfiles:\n",
       "    # JSONファイルを開く\n",
       "    with open(os.path.join(claims_path, filename), 'r') as file:\n",
       "        data = json.load(file)\n",
       "    claims[filename] = data"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "dac009d5-d558-4258-9735-4fb0de46c309",
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "# クレームを分析\n",
       "\n",
       "for filename in onlyfiles:\n",
       "    print(f\"***************************\")\n",
       "    print(f\"* クレーム: {filename}\")\n",
       "    print(f\"***************************\")\n",
       "    print(\"オリジナルコンテンツ:\")\n",
       "    print(\"-----------------\")\n",
       "    print(f\"件名: {claims[filename]['subject']}\\nコンテンツ:\\n{claims[filename]['content']}\\n\\n\")\n",
       "    print('分析結果:')\n",
       "    print(\"--------\")\n",
       "    text_input = f\"件名: {claims[filename]['subject']}\\nコンテンツ:\\n{claims[filename]['content']}\"\n",
       "    sentiment_query = \"このクレームを送信した人の感情はどうですか？\"\n",
       "    location_query = \"クレームに関連する出来事が発生した場所はどこですか？\"\n",
       "    time_query = \"クレームに関連する出来事が発生した日時はいつですか？可能であれば、具体的な日付と時間を教えてください。\"\n",
       "    print(f\"- 感情: \")\n",
       "    conversation.predict(text=text_input, query=sentiment_query);\n",
       "    print(\"\\n- 場所: \")\n",
       "    conversation.predict(text=text_input, query=location_query);\n",
       "    print(\"\\n- 日時: \")\n",
       "    conversation.predict(text=text_input, query=time_query);\n",
       "    print(\"\\n\\n                          ----====----\\n\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "6e28a5b0-6c93-42ba-84dd-42e17746d11d",
      "metadata": {},
      "source": [
       "必要に応じて、セクション3.7に戻って追加の演習を試してみてください。"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3.11",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
       "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 5
   }
   