apiVersion: serving.kserve.io/v1alpha1
kind: ServingRuntime
metadata:
  annotations:
    opendatahub.io/accelerator-name: ""
    opendatahub.io/apiProtocol: REST
    opendatahub.io/recommended-accelerators: '["nvidia.com/gpu"]'
    opendatahub.io/template-display-name: OpenVINO Model Server
    opendatahub.io/template-name: kserve-ovms
    openshift.io/display-name: kserve-ovms
  labels:
    opendatahub.io/dashboard: "true"
  name: accident-detect-kserve-ovms
  namespace: user1
spec:
  annotations:
    prometheus.kserve.io/path: /metrics
    prometheus.kserve.io/port: "8888"
  containers:
  - args:
    - --model_name={{.Name}}
    - --port=8001
    - --rest_port=8888
    - --model_path=/mnt/models
    - --file_system_poll_wait_seconds=0
    - --grpc_bind_address=127.0.0.1
    - --rest_bind_address=127.0.0.1
    - --target_device=AUTO
    - --metrics_enable
    image: quay.io/modh/openvino_model_server@sha256:5d04d405526ea4ce5b807d0cd199ccf7f71bab1228907c091e975efa770a4908
    name: kserve-container
    ports:
    - containerPort: 8888
      protocol: TCP
    resources:
      limits:
        cpu: "2"
        memory: 8Gi
      requests:
        cpu: "1"
        memory: 4Gi
    volumeMounts:
    - mountPath: /dev/shm
      name: shm
  multiModel: false
  protocolVersions:
  - v2
  - grpc-v2
  supportedModelFormats:
  - autoSelect: true
    name: openvino_ir
    version: opset13
  - name: onnx
    version: "1"
  - autoSelect: true
    name: tensorflow
    version: "1"
  - autoSelect: true
    name: tensorflow
    version: "2"
  - autoSelect: true
    name: paddle
    version: "2"
  - autoSelect: true
    name: pytorch
    version: "2"
  volumes:
  - emptyDir:
      medium: Memory
      sizeLimit: 2Gi
    name: shm
